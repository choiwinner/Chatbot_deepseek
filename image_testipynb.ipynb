{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base64(pil_image):\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    #img_str = base64.b64encode(buffered.read()).decode(\"utf-8\")\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"2.jpg\"\n",
    "pil_image = Image.open(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_b64= convert_to_base64(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def prompt_func(data):\n",
    "    text = data['text']\n",
    "    image = data['image']\n",
    "\n",
    "    image_part = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": f\"data:image/jpg;base64,{image}\",\n",
    "    }\n",
    "\n",
    "    content_parts = []\n",
    "\n",
    "    text_part = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": text\n",
    "    }\n",
    "\n",
    "    content_parts.append(image_part)\n",
    "    content_parts.append(text_part)\n",
    "\n",
    "    return [HumanMessage(content=content_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model='gemma3:12b', temperature=0.7)\n",
    "\n",
    "chain = prompt_func | llm | StrOutputParser()\n",
    "\n",
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요! 무엇을 도와드릴까요? 😊\\n' additional_kwargs={} response_metadata={'model': 'gemma3:12b', 'created_at': '2025-03-25T17:55:23.5808775Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14434564600, 'load_duration': 11831035700, 'prompt_eval_count': 10, 'prompt_eval_duration': 1116000000, 'eval_count': 11, 'eval_duration': 1485000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-91f2455e-084b-43c3-801a-5b4f7f961fde-0' usage_metadata={'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21}\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"안녕하세요\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지는 두 가지 데이터의 시계열 그래프를 보여줍니다.\n",
      "\n",
      "**그래프 개요:**\n",
      "\n",
      "*   **축:**\n",
      "    *   **가로축 (X축):** 시간 (2018년 1월 ~ 2024년 9월)\n",
      "    *   **세로축 (Y축):** 지수 (숫자 값)\n",
      "*   **선:** 두 개의 선이 있습니다.\n",
      "    *   **빨간색 선:** \"평균\"을 나타냅니다.\n",
      "    *   **초록색 선:** \"중위\"를 나타냅니다.\n",
      "\n",
      "**데이터 추세:**\n",
      "\n",
      "*   **평균 (빨간색 선):** 2018년 초부터 2019년 초까지 상승 추세를 보이다가 하락세를 보입니다. 이후 변동성을 보이며 2024년 9월까지 유지됩니다.\n",
      "*   **중위 (초록색 선):** 2018년 초부터 2019년 초까지 상승 추세를 보이다가 하락세를 보입니다. 이후 변동성을 보이며 2024년 9월까지 유지됩니다.\n",
      "\n",
      "**전반적인 관점:**\n",
      "\n",
      "두 선 모두 비슷한 추세를 보이지만, 중위선이 평균선보다 약간 높은 값을 나타내는 경향이 있습니다. 두 데이터 모두 변동성이 큰 모습을 보입니다.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({'text': '이미지를 설명해주세요.', 'image': image_b64})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
