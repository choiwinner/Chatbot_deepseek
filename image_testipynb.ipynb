{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base64(pil_image):\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    #img_str = base64.b64encode(buffered.read()).decode(\"utf-8\")\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"2.jpg\"\n",
    "pil_image = Image.open(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_b64= convert_to_base64(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def prompt_func(data):\n",
    "    text = data['text']\n",
    "    image = data['image']\n",
    "\n",
    "    image_part = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": f\"data:image/jpg;base64,{image}\",\n",
    "    }\n",
    "\n",
    "    content_parts = []\n",
    "\n",
    "    text_part = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": text\n",
    "    }\n",
    "\n",
    "    content_parts.append(image_part)\n",
    "    content_parts.append(text_part)\n",
    "\n",
    "    return [HumanMessage(content=content_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model='gemma3:12b', temperature=0.7)\n",
    "\n",
    "chain = prompt_func | llm | StrOutputParser()\n",
    "\n",
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\\n' additional_kwargs={} response_metadata={'model': 'gemma3:12b', 'created_at': '2025-03-25T17:55:23.5808775Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14434564600, 'load_duration': 11831035700, 'prompt_eval_count': 10, 'prompt_eval_duration': 1116000000, 'eval_count': 11, 'eval_duration': 1485000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-91f2455e-084b-43c3-801a-5b4f7f961fde-0' usage_metadata={'input_tokens': 10, 'output_tokens': 11, 'total_tokens': 21}\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ë¯¸ì§€ëŠ” ë‘ ê°€ì§€ ë°ì´í„°ì˜ ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "\n",
      "**ê·¸ë˜í”„ ê°œìš”:**\n",
      "\n",
      "*   **ì¶•:**\n",
      "    *   **ê°€ë¡œì¶• (Xì¶•):** ì‹œê°„ (2018ë…„ 1ì›” ~ 2024ë…„ 9ì›”)\n",
      "    *   **ì„¸ë¡œì¶• (Yì¶•):** ì§€ìˆ˜ (ìˆ«ì ê°’)\n",
      "*   **ì„ :** ë‘ ê°œì˜ ì„ ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   **ë¹¨ê°„ìƒ‰ ì„ :** \"í‰ê· \"ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "    *   **ì´ˆë¡ìƒ‰ ì„ :** \"ì¤‘ìœ„\"ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "**ë°ì´í„° ì¶”ì„¸:**\n",
      "\n",
      "*   **í‰ê·  (ë¹¨ê°„ìƒ‰ ì„ ):** 2018ë…„ ì´ˆë¶€í„° 2019ë…„ ì´ˆê¹Œì§€ ìƒìŠ¹ ì¶”ì„¸ë¥¼ ë³´ì´ë‹¤ê°€ í•˜ë½ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤. ì´í›„ ë³€ë™ì„±ì„ ë³´ì´ë©° 2024ë…„ 9ì›”ê¹Œì§€ ìœ ì§€ë©ë‹ˆë‹¤.\n",
      "*   **ì¤‘ìœ„ (ì´ˆë¡ìƒ‰ ì„ ):** 2018ë…„ ì´ˆë¶€í„° 2019ë…„ ì´ˆê¹Œì§€ ìƒìŠ¹ ì¶”ì„¸ë¥¼ ë³´ì´ë‹¤ê°€ í•˜ë½ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤. ì´í›„ ë³€ë™ì„±ì„ ë³´ì´ë©° 2024ë…„ 9ì›”ê¹Œì§€ ìœ ì§€ë©ë‹ˆë‹¤.\n",
      "\n",
      "**ì „ë°˜ì ì¸ ê´€ì :**\n",
      "\n",
      "ë‘ ì„  ëª¨ë‘ ë¹„ìŠ·í•œ ì¶”ì„¸ë¥¼ ë³´ì´ì§€ë§Œ, ì¤‘ìœ„ì„ ì´ í‰ê· ì„ ë³´ë‹¤ ì•½ê°„ ë†’ì€ ê°’ì„ ë‚˜íƒ€ë‚´ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ë‘ ë°ì´í„° ëª¨ë‘ ë³€ë™ì„±ì´ í° ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({'text': 'ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.', 'image': image_b64})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py31012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
